{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "This notebook explores the cleaned dataset to uncover key insights and relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the Cleaned Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the cleaned dataset\n",
        "file_path = '../data/processed/cleaned_data_20241226_225801.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "print(f\"Dataset loaded with {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Unique year-category combinations:\", df['year_category'].unique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Missing Values Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate and display the percentage of missing values for each column\n",
        "missing_ratio = (df.isnull().sum() / len(df)) * 100\n",
        "print(\"Missing Values Ratio (%):\")\n",
        "print(missing_ratio.sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize original distribution of 'data_value'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['data_value'], kde=True, bins=30, color='blue')\n",
        "plt.title('Distribution of Data Value')\n",
        "plt.xlabel('Data Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Visualize log-transformed distribution for better spread\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['data_value'].apply(lambda x: np.log1p(x) if x > 0 else 0), kde=True, bins=30, color='green')\n",
        "plt.title('Log-Transformed Distribution of Data Value')\n",
        "plt.xlabel('Log(Data Value)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove non-numeric columns and generate a correlation matrix\n",
        "df_numeric = df.select_dtypes(include=['float64', 'int64'])\n",
        "plt.figure(figsize=(12, 8))\n",
        "corr_matrix = df_numeric.corr()\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Category Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze data by category\n",
        "category_summary = df.groupby('category')['data_value'].mean().sort_values(ascending=False)\n",
        "print(category_summary)\n",
        "\n",
        "# Enhanced bar graph with annotations\n",
        "category_summary.plot(kind='bar', figsize=(12, 6), title='Average Data Value by Category', color='skyblue')\n",
        "plt.ylabel('Average Data Value')\n",
        "plt.xticks(rotation=45)\n",
        "for i, v in enumerate(category_summary):\n",
        "    plt.text(i, v + 0.5, f\"{v:.2f}\", ha='center', va='bottom')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np  # Import numpy for numerical operations\n",
        "\n",
        "def display_high_correlations(df: pd.DataFrame, threshold: float = 0.7):\n",
        "    \"\"\"\n",
        "    Display columns with correlations above the given threshold.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The DataFrame containing the data.\n",
        "    threshold (float): The correlation threshold to consider as high.\n",
        "    \"\"\"\n",
        "    # Compute correlation matrix\n",
        "    corr_matrix = df.corr()\n",
        "\n",
        "    # Flatten the matrix into a series with column pairs\n",
        "    corr_pairs = (\n",
        "        corr_matrix.where(~np.tril(np.ones(corr_matrix.shape)).astype(bool))\n",
        "        .stack()\n",
        "        .reset_index()\n",
        "    )\n",
        "    corr_pairs.columns = [\"Column 1\", \"Column 2\", \"Correlation\"]\n",
        "    high_corrs = corr_pairs[abs(corr_pairs[\"Correlation\"]) > threshold]\n",
        "\n",
        "    if not high_corrs.empty:\n",
        "        print(\"Columns with high correlations:\")\n",
        "        for _, row in high_corrs.iterrows():\n",
        "            print(f\"{row['Column 1']} and {row['Column 2']}: Correlation = {row['Correlation']:.2f}\")\n",
        "    else:\n",
        "        print(\"No correlations above the threshold.\")\n",
        "        \n",
        "# Select numeric columns\n",
        "numeric_columns = df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Display high correlations with a threshold of 0.7\n",
        "display_high_correlations(numeric_columns, threshold=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "year_summary = df.groupby('year')[['data_value', 'low_confidence_limit', 'high_confidence_limit']].mean()\n",
        "print(year_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df['totalpopulation'].equals(df['totalpop18plus']):\n",
        "    df = df.drop(columns=['totalpop18plus'])\n",
        "    print(\"totalpop18plus column dropped.\")\n",
        "else:\n",
        "    print(\"totalpop18plus column not dropped.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install geopandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['longitude'], df['latitude']))\n",
        "gdf.plot(column='data_value', legend=True, cmap='viridis')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state_summary = df.groupby('statedesc')['data_value'].mean().sort_values(ascending=False)\n",
        "print(state_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gdf[gdf['category'] == 'Prevention'].plot(column='data_value', legend=True, cmap='coolwarm')\n",
        "plt.title(\"Prevention Category: Data Value by Location\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "yearly_category = df.groupby(['year', 'category'])['data_value'].mean().unstack()\n",
        "yearly_category.plot(kind='bar', figsize=(10, 6))\n",
        "plt.title(\"Yearly Trends by Category\")\n",
        "plt.ylabel(\"Average Data Value\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
